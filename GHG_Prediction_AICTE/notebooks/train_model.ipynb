{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b84351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# File and sheet handling\n",
    "# -------------------------\n",
    "excel_path = \"Data_Set.xlsx\"\n",
    "excel_file = pd.ExcelFile(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38659c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only '_Summary_Commodity' sheets\n",
    "commodity_sheets = [sheet for sheet in excel_file.sheet_names if sheet.endswith('_Summary_Commodity')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns (X) and Target column (y)\n",
    "feature_cols = [\n",
    "    'Supply Chain Emission Factors without Margins',\n",
    "    'Margins of Supply Chain Emission Factors',\n",
    "    'DQ ReliabilityScore of Factors without Margins',\n",
    "    'DQ TemporalCorrelation of Factors without Margins',\n",
    "    'DQ GeographicalCorrelation of Factors without Margins',\n",
    "    'DQ TechnologicalCorrelation of Factors without Margins',\n",
    "    'DQ DataCollection of Factors without Margins'\n",
    "]\n",
    "target_col = 'Supply Chain Emission Factors with Margins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b74e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Load and combine all sheets\n",
    "# -------------------------\n",
    "dataframes = []\n",
    "for sheet in commodity_sheets:\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet)\n",
    "    if all(col in df.columns for col in feature_cols + [target_col]):\n",
    "        df = df[feature_cols + [target_col]].dropna()\n",
    "        dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ecaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data from all sheets\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d37646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Split data\n",
    "# -------------------------\n",
    "X = combined_df[feature_cols]\n",
    "y = combined_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08543b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00069bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Scale the data\n",
    "# -------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Train RandomForestRegressor\n",
    "# -------------------------\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec720834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Evaluation\n",
    "# -------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"âœ… Trained on {len(X)} rows from {len(commodity_sheets)} sheets\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Save model and scaler\n",
    "# -------------------------\n",
    "joblib.dump(model, 'models/random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "joblib.dump(feature_cols, 'models/feature_columns.pkl')  # Save feature order for inference\n",
    "print(\"ðŸ’¾ Saved: random_forest_model.pkl, scaler.pkl, feature_columns.pkl\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
